{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# 06 - Custom Transformers\n",
    "\n",
    "This notebook covers how to build your own transformers for Nebula pipelines.\n",
    "\n",
    "| Part | Topic |\n",
    "|------|-------|\n",
    "| **1** | The Transformer Base Class |\n",
    "| **2** | Narwhals-Native Transformers |\n",
    "| **3** | Backend-Specific Transformers |\n",
    "| **4** | Column Selection Helpers |\n",
    "| **5** | Parameter Tracking & Descriptions |\n",
    "| **6** | Duck-Typed Transformers |\n",
    "| **7** | Best Practices |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import narwhals as nw\n",
    "import polars as pl\n",
    "\n",
    "from nebula import TransformerPipeline\n",
    "from nebula.base import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sample-data",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>order_id</th><th>customer</th><th>amount</th><th>status</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;alice&quot;</td><td>150.0</td><td>&quot;shipped&quot;</td></tr><tr><td>2</td><td>&quot;bob&quot;</td><td>75.0</td><td>&quot;pending&quot;</td></tr><tr><td>3</td><td>&quot;alice&quot;</td><td>200.0</td><td>&quot;shipped&quot;</td></tr><tr><td>4</td><td>&quot;carol&quot;</td><td>50.0</td><td>&quot;pending&quot;</td></tr><tr><td>5</td><td>&quot;bob&quot;</td><td>300.0</td><td>&quot;delivered&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────────┬──────────┬────────┬───────────┐\n",
       "│ order_id ┆ customer ┆ amount ┆ status    │\n",
       "│ ---      ┆ ---      ┆ ---    ┆ ---       │\n",
       "│ i64      ┆ str      ┆ f64    ┆ str       │\n",
       "╞══════════╪══════════╪════════╪═══════════╡\n",
       "│ 1        ┆ alice    ┆ 150.0  ┆ shipped   │\n",
       "│ 2        ┆ bob      ┆ 75.0   ┆ pending   │\n",
       "│ 3        ┆ alice    ┆ 200.0  ┆ shipped   │\n",
       "│ 4        ┆ carol    ┆ 50.0   ┆ pending   │\n",
       "│ 5        ┆ bob      ┆ 300.0  ┆ delivered │\n",
       "└──────────┴──────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = pl.DataFrame({\n",
    "    \"order_id\": [1, 2, 3, 4, 5],\n",
    "    \"customer\": [\"alice\", \"bob\", \"alice\", \"carol\", \"bob\"],\n",
    "    \"amount\": [150.0, 75.0, 200.0, 50.0, 300.0],\n",
    "    \"status\": [\"shipped\", \"pending\", \"shipped\", \"pending\", \"delivered\"],\n",
    "})\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: The Transformer Base Class\n",
    "\n",
    "All Nebula transformers inherit from `Transformer`. The base class provides:\n",
    "\n",
    "- **Automatic routing** between backends (pandas/polars/spark)\n",
    "- **Parameter tracking** for visualization and debugging\n",
    "- **Column selection helpers** for flexible column matching\n",
    "- **Description support** for documentation\n",
    "\n",
    "### 1.1 The Routing Logic\n",
    "\n",
    "When you call `transform(df)`, the base class routes based on:\n",
    "\n",
    "```\n",
    "Input: Narwhals DataFrame\n",
    "├─ Has _transform_nw()? → Use it (nw → nw)\n",
    "└─ No _transform_nw()? → Convert to native → _select_transform() → Convert back\n",
    "\n",
    "Input: Native DataFrame (pandas/polars/spark)\n",
    "├─ Has _transform_nw()? → Wrap in nw → _transform_nw() → Unwrap\n",
    "└─ No _transform_nw()? → Use backend-specific method\n",
    "```\n",
    "\n",
    "**Key insight:** If you implement `_transform_nw()`, your transformer works with ALL backends automatically!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Narwhals-Native Transformers\n",
    "\n",
    "The recommended approach: implement `_transform_nw()` using the Narwhals API.\n",
    "\n",
    "### 2.1 Minimal Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minimal-transformer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌──────────┬──────────┬────────┬───────────┬───────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status    ┆ processed │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---       ┆ ---       │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str       ┆ bool      │\n",
      "╞══════════╪══════════╪════════╪═══════════╪═══════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ shipped   ┆ true      │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ pending   ┆ true      │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ shipped   ┆ true      │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ pending   ┆ true      │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ delivered ┆ true      │\n",
      "└──────────┴──────────┴────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "class AddProcessedFlag(Transformer):\n",
    "    \"\"\"Add a 'processed' column with value True.\"\"\"\n",
    "    \n",
    "    def _transform_nw(self, df):\n",
    "        return df.with_columns(nw.lit(True).alias(\"processed\"))\n",
    "\n",
    "\n",
    "# Test it\n",
    "t = AddProcessedFlag()\n",
    "result = t.transform(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "with-params-header",
   "metadata": {},
   "source": [
    "### 2.2 With Parameters\n",
    "\n",
    "**Important:** Always use keyword-only arguments (`*`) for transformer parameters. This ensures compatibility with config-driven pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parameterized-transformer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌──────────┬──────────┬────────┬───────────┬─────────────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status    ┆ amount_with_tax │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---       ┆ ---             │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str       ┆ f64             │\n",
      "╞══════════╪══════════╪════════╪═══════════╪═════════════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ shipped   ┆ 165.0           │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ pending   ┆ 82.5            │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ shipped   ┆ 220.0           │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ pending   ┆ 55.0            │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ delivered ┆ 330.0           │\n",
      "└──────────┴──────────┴────────┴───────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "class MultiplyColumn(Transformer):\n",
    "    \"\"\"Multiply a column by a factor.\"\"\"\n",
    "    \n",
    "    def __init__(self, *, column: str, factor: float, output_col: str | None = None):\n",
    "        super().__init__()  # Always call super().__init__()\n",
    "        self._column = column\n",
    "        self._factor = factor\n",
    "        self._output_col = output_col or column\n",
    "    \n",
    "    def _transform_nw(self, df):\n",
    "        expr = (nw.col(self._column) * self._factor).alias(self._output_col)\n",
    "        return df.with_columns(expr)\n",
    "\n",
    "\n",
    "# Test it\n",
    "t = MultiplyColumn(column=\"amount\", factor=1.1, output_col=\"amount_with_tax\")\n",
    "result = t.transform(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "in-pipeline-header",
   "metadata": {},
   "source": [
    "### 2.3 Using in Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "in-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:58,577 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:58,577 | [INFO]: Running 'MultiplyColumn' ... \n",
      "2026-02-09 09:50:58,582 | [INFO]: Completed 'MultiplyColumn' in 0.0s \n",
      "2026-02-09 09:50:58,582 | [INFO]: Running 'AddProcessedFlag' ... \n",
      "2026-02-09 09:50:58,582 | [INFO]: Completed 'AddProcessedFlag' in 0.0s \n",
      "2026-02-09 09:50:58,585 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (2 transformations)\n",
      " - MultiplyColumn -> PARAMS: column=\"amount\", factor=1.1, output_col=\"amount_with_tax\"\n",
      " - AddProcessedFlag\n",
      "shape: (5, 6)\n",
      "┌──────────┬──────────┬────────┬───────────┬─────────────────┬───────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status    ┆ amount_with_tax ┆ processed │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---       ┆ ---             ┆ ---       │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str       ┆ f64             ┆ bool      │\n",
      "╞══════════╪══════════╪════════╪═══════════╪═════════════════╪═══════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ shipped   ┆ 165.0           ┆ true      │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ pending   ┆ 82.5            ┆ true      │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ shipped   ┆ 220.0           ┆ true      │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ pending   ┆ 55.0            ┆ true      │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ delivered ┆ 330.0           ┆ true      │\n",
      "└──────────┴──────────┴────────┴───────────┴─────────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "pipe = TransformerPipeline([\n",
    "    MultiplyColumn(column=\"amount\", factor=1.1, output_col=\"amount_with_tax\"),\n",
    "    AddProcessedFlag(),\n",
    "])\n",
    "\n",
    "pipe.show(add_params=True)\n",
    "result = pipe.run(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Backend-Specific Transformers\n",
    "\n",
    "When Narwhals doesn't support what you need, implement backend-specific methods:\n",
    "\n",
    "- `_transform_pandas(self, df)` → Returns pandas DataFrame\n",
    "- `_transform_polars(self, df)` → Returns polars DataFrame\n",
    "- `_transform_spark(self, df)` → Returns Spark DataFrame\n",
    "\n",
    "The base class routes automatically via `_select_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "backend-specific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌──────────┬──────────┬────────┬───────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status    │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---       │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str       │\n",
      "╞══════════╪══════════╪════════╪═══════════╡\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ delivered │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ pending   │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ shipped   │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ pending   │\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ shipped   │\n",
      "└──────────┴──────────┴────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "class ReverseRows(Transformer):\n",
    "    \"\"\"Reverse row order - uses native APIs since Narwhals doesn't support this.\"\"\"\n",
    "    \n",
    "    def _transform_pandas(self, df):\n",
    "        return df.iloc[::-1].reset_index(drop=True)\n",
    "    \n",
    "    def _transform_polars(self, df):\n",
    "        return df.reverse()\n",
    "    \n",
    "    def _transform_spark(self, df):\n",
    "        from pyspark.sql import functions as F\n",
    "        from pyspark.sql.window import Window\n",
    "        \n",
    "        # Add row number, sort descending, drop helper column\n",
    "        w = Window.orderBy(F.monotonically_increasing_id())\n",
    "        return (\n",
    "            df.withColumn(\"_row_num\", F.row_number().over(w))\n",
    "            .orderBy(F.desc(\"_row_num\"))\n",
    "            .drop(\"_row_num\")\n",
    "        )\n",
    "\n",
    "\n",
    "# Test with Polars\n",
    "t = ReverseRows()\n",
    "result = t.transform(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "backend-pandas-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id customer  amount     status\n",
      "0         5      bob   300.0  delivered\n",
      "1         4    carol    50.0    pending\n",
      "2         3    alice   200.0    shipped\n",
      "3         2      bob    75.0    pending\n",
      "4         1    alice   150.0    shipped\n"
     ]
    }
   ],
   "source": [
    "# Also works with pandas\n",
    "orders_pd = orders.to_pandas()\n",
    "result_pd = t.transform(orders_pd)\n",
    "print(result_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-header",
   "metadata": {},
   "source": [
    "### 3.1 Hybrid Approach\n",
    "\n",
    "You can implement `_transform_nw()` for most cases and override for specific backends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hybrid-transformer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌──────────┬──────────┬────────┬─────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status  │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---     │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str     │\n",
      "╞══════════╪══════════╪════════╪═════════╡\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ pending │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ pending │\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ shipped │\n",
      "└──────────┴──────────┴────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "class DropDuplicates(Transformer):\n",
    "    \"\"\"Drop duplicate rows.\n",
    "    \n",
    "    Uses Narwhals for pandas/polars, but Spark needs special handling\n",
    "    because it preserves ordering differently.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *, columns: list[str] | None = None):\n",
    "        super().__init__()\n",
    "        self._columns = columns\n",
    "    \n",
    "    def transform(self, df):\n",
    "        # Check if Spark - use native API\n",
    "        df_type = type(df).__module__\n",
    "        if \"pyspark\" in df_type:\n",
    "            return self._transform_spark(df)\n",
    "        \n",
    "        # Otherwise use Narwhals\n",
    "        if not isinstance(df, (nw.DataFrame, nw.LazyFrame)):\n",
    "            df = nw.from_native(df)\n",
    "            result = self._transform_nw(df)\n",
    "            return nw.to_native(result)\n",
    "        return self._transform_nw(df)\n",
    "    \n",
    "    def _transform_nw(self, df):\n",
    "        if self._columns:\n",
    "            return df.unique(subset=self._columns)\n",
    "        return df.unique()\n",
    "    \n",
    "    def _transform_spark(self, df):\n",
    "        if self._columns:\n",
    "            return df.dropDuplicates(self._columns)\n",
    "        return df.dropDuplicates()\n",
    "\n",
    "\n",
    "# Test\n",
    "t = DropDuplicates(columns=[\"customer\"])\n",
    "result = t.transform(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Column Selection Helpers\n",
    "\n",
    "The base class provides helpers for flexible column selection (by name, regex, glob, prefix, suffix).\n",
    "\n",
    "### 4.1 Using `_set_columns_selections()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "column-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌──────────┬──────────┬────────┬───────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status    │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---       │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str       │\n",
      "╞══════════╪══════════╪════════╪═══════════╡\n",
      "│ 1        ┆ ALICE    ┆ 150.0  ┆ SHIPPED   │\n",
      "│ 2        ┆ BOB      ┆ 75.0   ┆ PENDING   │\n",
      "│ 3        ┆ ALICE    ┆ 200.0  ┆ SHIPPED   │\n",
      "│ 4        ┆ CAROL    ┆ 50.0   ┆ PENDING   │\n",
      "│ 5        ┆ BOB      ┆ 300.0  ┆ DELIVERED │\n",
      "└──────────┴──────────┴────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "class UppercaseColumns(Transformer):\n",
    "    \"\"\"Convert string columns to uppercase.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        columns: str | list[str] | None = None,\n",
    "        regex: str | None = None,\n",
    "        glob: str | None = None,\n",
    "        startswith: str | None = None,\n",
    "        endswith: str | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Register column selection criteria\n",
    "        self._set_columns_selections(\n",
    "            columns=columns,\n",
    "            regex=regex,\n",
    "            glob=glob,\n",
    "            startswith=startswith,\n",
    "            endswith=endswith,\n",
    "        )\n",
    "    \n",
    "    def _transform_nw(self, df):\n",
    "        # Get matching columns at runtime\n",
    "        selected = self._get_selected_columns(df)\n",
    "        \n",
    "        if not selected:\n",
    "            return df\n",
    "        \n",
    "        exprs = [nw.col(c).str.to_uppercase() for c in selected]\n",
    "        return df.with_columns(exprs)\n",
    "\n",
    "\n",
    "# Test with explicit columns\n",
    "t = UppercaseColumns(columns=[\"customer\", \"status\"])\n",
    "result = t.transform(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "column-selection-glob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns: ['customer']\n",
      "shape: (5, 4)\n",
      "┌──────────┬──────────┬────────┬───────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status    │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---       │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str       │\n",
      "╞══════════╪══════════╪════════╪═══════════╡\n",
      "│ 1        ┆ ALICE    ┆ 150.0  ┆ shipped   │\n",
      "│ 2        ┆ BOB      ┆ 75.0   ┆ pending   │\n",
      "│ 3        ┆ ALICE    ┆ 200.0  ┆ shipped   │\n",
      "│ 4        ┆ CAROL    ┆ 50.0   ┆ pending   │\n",
      "│ 5        ┆ BOB      ┆ 300.0  ┆ delivered │\n",
      "└──────────┴──────────┴────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Test with glob pattern\n",
    "t = UppercaseColumns(glob=\"*er\")  # Matches 'customer', 'order' columns\n",
    "result = t.transform(orders)\n",
    "print(f\"Selected columns: {t._get_selected_columns(orders)}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selection-options",
   "metadata": {},
   "source": [
    "### 4.2 Column Selection Options\n",
    "\n",
    "| Parameter | Description | Example |\n",
    "|-----------|-------------|---------|\n",
    "| `columns` | Explicit list | `[\"col_a\", \"col_b\"]` |\n",
    "| `regex` | Regular expression | `\"^amount_.*\"` |\n",
    "| `glob` | Shell-style pattern | `\"*_id\"` |\n",
    "| `startswith` | Column prefix | `\"order\"` |\n",
    "| `endswith` | Column suffix | `\"_at\"` |\n",
    "| `allow_excess_columns` | Allow missing columns | `True` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Parameter Tracking & Descriptions\n",
    "\n",
    "### 5.1 Automatic Parameter Tracking\n",
    "\n",
    "The `InitParamsStorage` metaclass automatically captures `__init__` parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "param-tracking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracked parameters:\n",
      "{'column': 'amount', 'factor': 1.1, 'output_col': 'new_amount'}\n"
     ]
    }
   ],
   "source": [
    "t = MultiplyColumn(column=\"amount\", factor=1.1, output_col=\"new_amount\")\n",
    "\n",
    "# Parameters are automatically captured\n",
    "print(\"Tracked parameters:\")\n",
    "print(t.transformer_init_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "param-in-show",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (1 transformation)\n",
      " - MultiplyColumn -> PARAMS: column=\"amount\", factor=1.1\n"
     ]
    }
   ],
   "source": [
    "# These appear in pipeline.show() and DAG visualization\n",
    "pipe = TransformerPipeline([\n",
    "    MultiplyColumn(column=\"amount\", factor=1.1),\n",
    "])\n",
    "pipe.show(add_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descriptions-header",
   "metadata": {},
   "source": [
    "### 5.2 Adding Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "descriptions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Apply 10% tax to order amounts\n",
      "*** Pipeline *** (1 transformation)\n",
      " - MultiplyColumn\n",
      "     Description: Apply 10% tax to order amounts\n"
     ]
    }
   ],
   "source": [
    "t = MultiplyColumn(column=\"amount\", factor=1.1)\n",
    "t.set_description(\"Apply 10% tax to order amounts\")\n",
    "\n",
    "print(f\"Description: {t.get_description()}\")\n",
    "\n",
    "# In pipelines, you can also use tuple syntax:\n",
    "pipe = TransformerPipeline([\n",
    "    (MultiplyColumn(column=\"amount\", factor=1.1), \"Apply 10% tax to order amounts\"),\n",
    "])\n",
    "pipe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Duck-Typed Transformers\n",
    "\n",
    "You don't *have* to inherit from `Transformer`. Any object with a valid `transform(df)` method works.\n",
    "\n",
    "### 6.1 Requirements\n",
    "\n",
    "A duck-typed transformer must have:\n",
    "- A `transform` method\n",
    "- First parameter is positional (the DataFrame)\n",
    "- Additional parameters must have defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "duck-typed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:58,654 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:58,659 | [INFO]: Running 'SimpleDuckTransformer' ... \n",
      "2026-02-09 09:50:58,660 | [INFO]: Completed 'SimpleDuckTransformer' in 0.0s \n",
      "2026-02-09 09:50:58,661 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌──────────┬──────────┬────────┬───────────┬────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ status    ┆ source │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---       ┆ ---    │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str       ┆ str    │\n",
      "╞══════════╪══════════╪════════╪═══════════╪════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ shipped   ┆ duck   │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ pending   ┆ duck   │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ shipped   ┆ duck   │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ pending   ┆ duck   │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ delivered ┆ duck   │\n",
      "└──────────┴──────────┴────────┴───────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "class SimpleDuckTransformer:\n",
    "    \"\"\"No inheritance needed - just implement transform().\"\"\"\n",
    "    \n",
    "    def transform(self, df):\n",
    "        # Works with any backend\n",
    "        if not isinstance(df, (nw.DataFrame, nw.LazyFrame)):\n",
    "            df_nw = nw.from_native(df)\n",
    "            result = df_nw.with_columns(nw.lit(\"duck\").alias(\"source\"))\n",
    "            return nw.to_native(result)\n",
    "        return df.with_columns(nw.lit(\"duck\").alias(\"source\"))\n",
    "\n",
    "\n",
    "# Use in pipeline\n",
    "pipe = TransformerPipeline([\n",
    "    SimpleDuckTransformer(),\n",
    "])\n",
    "\n",
    "result = pipe.run(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "duck-with-defaults",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (1 transformation)\n",
      " - DuckWithOptions\n"
     ]
    }
   ],
   "source": [
    "class DuckWithOptions:\n",
    "    \"\"\"Duck-typed with optional parameters (must have defaults).\"\"\"\n",
    "    \n",
    "    def transform(self, df, prefix=\"col_\", debug=False):\n",
    "        if debug:\n",
    "            print(f\"Processing with prefix: {prefix}\")\n",
    "        # ... transformation logic\n",
    "        return df\n",
    "\n",
    "\n",
    "# Valid - extra params have defaults\n",
    "pipe = TransformerPipeline([DuckWithOptions()])\n",
    "pipe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duck-validation",
   "metadata": {},
   "source": [
    "### 6.2 Validation\n",
    "\n",
    "Nebula validates duck-typed transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "duck-validation-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidDuck: True\n",
      "InvalidDuck: False\n",
      "AlsoInvalid: False\n"
     ]
    }
   ],
   "source": [
    "from nebula.pipelines.transformer_type_util import is_duck_typed_transformer\n",
    "\n",
    "\n",
    "class ValidDuck:\n",
    "    def transform(self, df): return df\n",
    "\n",
    "class InvalidDuck:\n",
    "    def transform(self): return None  # No df parameter!\n",
    "\n",
    "class AlsoInvalid:\n",
    "    def transform(self, df, required_param): return df  # No default!\n",
    "\n",
    "print(f\"ValidDuck: {is_duck_typed_transformer(ValidDuck())}\")\n",
    "print(f\"InvalidDuck: {is_duck_typed_transformer(InvalidDuck())}\")\n",
    "print(f\"AlsoInvalid: {is_duck_typed_transformer(AlsoInvalid())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Best Practices\n",
    "\n",
    "### 7.1 Always Call `super().__init__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bp-super-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrectTransformer(Transformer):\n",
    "    def __init__(self, *, value: int):\n",
    "        super().__init__()  # ← Required for parameter tracking\n",
    "        self._value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bp-kwargs",
   "metadata": {},
   "source": [
    "### 7.2 Use Keyword-Only Arguments\n",
    "\n",
    "All parameters after `*` are keyword-only, ensuring config compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bp-kwargs-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodTransformer(Transformer):\n",
    "    def __init__(self, *, column: str, value: int):  # ← keyword-only\n",
    "        super().__init__()\n",
    "        # ...\n",
    "\n",
    "# Works with config:\n",
    "# {\"transformer\": \"GoodTransformer\", \"params\": {\"column\": \"x\", \"value\": 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bp-narwhals",
   "metadata": {},
   "source": [
    "### 7.3 Prefer Narwhals for Multi-Backend Support\n",
    "\n",
    "Use `_transform_nw()` whenever possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bp-narwhals-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortableTransformer(Transformer):\n",
    "    \"\"\"Works with pandas, polars, and spark - no extra code!\"\"\"\n",
    "    \n",
    "    def __init__(self, *, column: str):\n",
    "        super().__init__()\n",
    "        self._column = column\n",
    "    \n",
    "    def _transform_nw(self, df):\n",
    "        return df.filter(nw.col(self._column).is_not_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bp-typing",
   "metadata": {},
   "source": [
    "### 7.4 Type Hints for Clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bp-typing-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "class WellTypedTransformer(Transformer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        columns: str | list[str],\n",
    "        threshold: float = 0.0,\n",
    "        exclude: Iterable[str] | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bp-validation",
   "metadata": {},
   "source": [
    "### 7.5 Validate in `__init__`, Not `transform`\n",
    "\n",
    "Fail fast with clear errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bp-validation-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught: threshold must be between 0 and 1, got 1.5\n"
     ]
    }
   ],
   "source": [
    "class ValidatingTransformer(Transformer):\n",
    "    def __init__(self, *, threshold: float):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Validate early\n",
    "        if not 0.0 <= threshold <= 1.0:\n",
    "            raise ValueError(f\"threshold must be between 0 and 1, got {threshold}\")\n",
    "        \n",
    "        self._threshold = threshold\n",
    "\n",
    "\n",
    "try:\n",
    "    t = ValidatingTransformer(threshold=1.5)\n",
    "except ValueError as e:\n",
    "    print(f\"Caught: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Pattern | When to Use |\n",
    "|---------|-------------|\n",
    "| `_transform_nw()` | **Default** - works across all backends |\n",
    "| `_transform_pandas/polars/spark()` | Backend-specific features |\n",
    "| `_set_columns_selections()` | Flexible column matching |\n",
    "| Duck-typed | Quick prototypes, external libs |\n",
    "\n",
    "**Checklist for new transformers:**\n",
    "1. ✅ Inherit from `Transformer`\n",
    "2. ✅ Call `super().__init__()`\n",
    "3. ✅ Use keyword-only args (`*`)\n",
    "4. ✅ Implement `_transform_nw()` if possible\n",
    "5. ✅ Add type hints\n",
    "6. ✅ Validate in `__init__`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
