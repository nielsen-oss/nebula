{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# 05 - Configuration-Driven Pipelines\n",
    "\n",
    "Nebula pipelines can be defined entirely in configuration (JSON/YAML), enabling:\n",
    "\n",
    "- **Separation of concerns** - Data engineers define configs, code stays stable\n",
    "- **Environment flexibility** - Different configs for dev/prod/regions\n",
    "- **No-code changes** - Adjust pipelines without redeploying\n",
    "\n",
    "| Part | Topic |\n",
    "|------|-------|\n",
    "| **1** | Basic Configuration |\n",
    "| **2** | Transformer Options |\n",
    "| **3** | Custom Transformers & Functions |\n",
    "| **4** | Lazy Parameters (`__ns__`) |\n",
    "| **5** | Loops (Dynamic Expansion) |\n",
    "| **6** | Full Examples |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "from nebula.base import Transformer\n",
    "from nebula.pipelines.pipeline_loader import load_pipeline\n",
    "from nebula.storage import nebula_storage as ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sample-data",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>order_id</th><th>customer</th><th>amount</th><th>region</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;alice&quot;</td><td>150.0</td><td>&quot;US&quot;</td></tr><tr><td>2</td><td>&quot;bob&quot;</td><td>75.0</td><td>&quot;EU&quot;</td></tr><tr><td>3</td><td>&quot;alice&quot;</td><td>200.0</td><td>&quot;US&quot;</td></tr><tr><td>4</td><td>&quot;carol&quot;</td><td>50.0</td><td>&quot;APAC&quot;</td></tr><tr><td>5</td><td>&quot;bob&quot;</td><td>300.0</td><td>&quot;EU&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────────┬──────────┬────────┬────────┐\n",
       "│ order_id ┆ customer ┆ amount ┆ region │\n",
       "│ ---      ┆ ---      ┆ ---    ┆ ---    │\n",
       "│ i64      ┆ str      ┆ f64    ┆ str    │\n",
       "╞══════════╪══════════╪════════╪════════╡\n",
       "│ 1        ┆ alice    ┆ 150.0  ┆ US     │\n",
       "│ 2        ┆ bob      ┆ 75.0   ┆ EU     │\n",
       "│ 3        ┆ alice    ┆ 200.0  ┆ US     │\n",
       "│ 4        ┆ carol    ┆ 50.0   ┆ APAC   │\n",
       "│ 5        ┆ bob      ┆ 300.0  ┆ EU     │\n",
       "└──────────┴──────────┴────────┴────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = pl.DataFrame({\n",
    "    \"order_id\": [1, 2, 3, 4, 5],\n",
    "    \"customer\": [\"alice\", \"bob\", \"alice\", \"carol\", \"bob\"],\n",
    "    \"amount\": [150.0, 75.0, 200.0, 50.0, 300.0],\n",
    "    \"region\": [\"US\", \"EU\", \"US\", \"APAC\", \"EU\"],\n",
    "})\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Basic Configuration\n",
    "\n",
    "The `load_pipeline` function accepts a Python dict (which can come from JSON or YAML files).\n",
    "\n",
    "### 1.1 Minimal Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "basic-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (2 transformations)\n",
      " - SelectColumns -> PARAMS: columns=['order_id', 'amount']\n",
      " - AssertNotEmpty\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\"transformer\": \"SelectColumns\", \"params\": {\"columns\": [\"order_id\", \"amount\"]}},\n",
    "        {\"transformer\": \"AssertNotEmpty\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show(add_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic-run",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,034 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,035 | [INFO]: Running 'SelectColumns' ... \n",
      "2026-02-09 09:50:33,043 | [INFO]: Completed 'SelectColumns' in 0.0s \n",
      "2026-02-09 09:50:33,044 | [INFO]: Running 'AssertNotEmpty' ... \n",
      "2026-02-09 09:50:33,044 | [INFO]: Completed 'AssertNotEmpty' in 0.0s \n",
      "2026-02-09 09:50:33,045 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌──────────┬────────┐\n",
      "│ order_id ┆ amount │\n",
      "│ ---      ┆ ---    │\n",
      "│ i64      ┆ f64    │\n",
      "╞══════════╪════════╡\n",
      "│ 1        ┆ 150.0  │\n",
      "│ 2        ┆ 75.0   │\n",
      "│ 3        ┆ 200.0  │\n",
      "│ 4        ┆ 50.0   │\n",
      "│ 5        ┆ 300.0  │\n",
      "└──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = pipe.run(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "from-file-header",
   "metadata": {},
   "source": [
    "### 1.2 Loading from Files\n",
    "\n",
    "In practice, configs come from files:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import yaml  # pip install pyyaml\n",
    "\n",
    "# From JSON\n",
    "with open(\"pipeline.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# From YAML\n",
    "with open(\"pipeline.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-options-header",
   "metadata": {},
   "source": [
    "### 1.3 Pipeline-Level Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pipeline-options",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Order Processing *** (1 transformation)\n",
      " - Filter\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"name\": \"Order Processing\",\n",
    "    \"df_input_name\": \"Raw Orders\",\n",
    "    \"df_output_name\": \"Processed Orders\",\n",
    "    \"pipeline\": [\n",
    "        {\"transformer\": \"Filter\", \"params\": {\n",
    "            \"input_col\": \"amount\",\n",
    "            \"perform\": \"keep\",\n",
    "            \"operator\": \"gt\",\n",
    "            \"value\": 100\n",
    "        }},\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Transformer Options\n",
    "\n",
    "Each transformer entry supports these keys:\n",
    "\n",
    "| Key | Required | Description |\n",
    "|-----|----------|-------------|\n",
    "| `transformer` | Yes | Transformer class name |\n",
    "| `params` | No | Dict of constructor parameters |\n",
    "| `description` | No | Human-readable description |\n",
    "| `lazy` | No | If `true`, wrap in LazyWrapper |\n",
    "| `skip` | No | If `true`, skip this transformer |\n",
    "| `perform` | No | If `false`, skip this transformer |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "transformer-options",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,056 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,056 | [INFO]: Running 'Filter' ... \n",
      "2026-02-09 09:50:33,056 | [INFO]: Completed 'Filter' in 0.0s \n",
      "2026-02-09 09:50:33,056 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (1 transformation)\n",
      " - Filter\n",
      "     Description: Keep only high-value orders\n",
      "\n",
      "Columns: ['order_id', 'customer', 'amount', 'region']\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"transformer\": \"Filter\",\n",
    "            \"description\": \"Keep only high-value orders\",\n",
    "            \"params\": {\n",
    "                \"input_col\": \"amount\",\n",
    "                \"perform\": \"keep\",\n",
    "                \"operator\": \"gt\",\n",
    "                \"value\": 100\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"transformer\": \"DropColumns\",\n",
    "            \"skip\": True,  # This transformer is skipped\n",
    "            \"params\": {\"columns\": \"region\"}\n",
    "        },\n",
    "        {\n",
    "            \"transformer\": \"SelectColumns\",\n",
    "            \"perform\": False,  # Same as skip: True\n",
    "            \"params\": {\"columns\": [\"order_id\"]}\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show()\n",
    "\n",
    "# Only Filter runs - DropColumns and SelectColumns are skipped\n",
    "result = pipe.run(orders)\n",
    "print(f\"\\nColumns: {result.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skip-feature-flags",
   "metadata": {},
   "source": [
    "### 2.1 Feature Flags with Skip/Perform\n",
    "\n",
    "Use environment variables or config flags to conditionally enable transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feature-flags",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (1 transformation)\n",
      " - AddLiterals\n",
      "     Description: Add discount flag\n"
     ]
    }
   ],
   "source": [
    "# Simulate feature flags\n",
    "ENABLE_EXPENSIVE_VALIDATION = False\n",
    "ENABLE_DISCOUNT = True\n",
    "\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"transformer\": \"AssertCount\",\n",
    "            \"description\": \"Expensive row count validation\",\n",
    "            \"perform\": ENABLE_EXPENSIVE_VALIDATION,\n",
    "            \"params\": {\"min_count\": 1}\n",
    "        },\n",
    "        {\n",
    "            \"transformer\": \"AddLiterals\",\n",
    "            \"description\": \"Add discount flag\",\n",
    "            \"perform\": ENABLE_DISCOUNT,\n",
    "            \"params\": {\n",
    "                \"data\": [{\"alias\": \"has_discount\", \"value\": True}]\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "storage-keywords",
   "metadata": {},
   "source": [
    "### 2.2 Storage Keywords in Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "storage-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,066 | [INFO]: Nebula Storage: clear. \n",
      "2026-02-09 09:50:33,066 | [INFO]: Nebula Storage: 0 keys remained after clearing. \n",
      "2026-02-09 09:50:33,066 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,066 | [INFO]: Running 'Filter' ... \n",
      "2026-02-09 09:50:33,066 | [INFO]: Completed 'Filter' in 0.0s \n",
      "2026-02-09 09:50:33,066 | [INFO]:    --> Store df with key \"filtered_orders\" \n",
      "2026-02-09 09:50:33,066 | [INFO]: Nebula Storage: setting an object (<class 'polars.dataframe.frame.DataFrame'>) with the key \"filtered_orders\". \n",
      "2026-02-09 09:50:33,066 | [INFO]: Running 'SelectColumns' ... \n",
      "2026-02-09 09:50:33,066 | [INFO]: Completed 'SelectColumns' in 0.0s \n",
      "2026-02-09 09:50:33,066 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (2 transformations)\n",
      " - Filter\n",
      "   --> Store df with key \"filtered_orders\"\n",
      " - SelectColumns\n",
      "\n",
      "Stored keys: ['filtered_orders']\n"
     ]
    }
   ],
   "source": [
    "ns.clear()\n",
    "\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\"transformer\": \"Filter\", \"params\": {\n",
    "            \"input_col\": \"amount\", \"perform\": \"keep\", \"operator\": \"gt\", \"value\": 100\n",
    "        }},\n",
    "        {\"store\": \"filtered_orders\"},\n",
    "        {\"transformer\": \"SelectColumns\", \"params\": {\"columns\": [\"order_id\", \"amount\"]}},\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show()\n",
    "\n",
    "result = pipe.run(orders)\n",
    "print(f\"\\nStored keys: {ns.list_keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Custom Transformers & Functions\n",
    "\n",
    "To use transformers not in Nebula's core, pass them via `extra_transformers`. For split/branch functions, use `extra_functions`.\n",
    "\n",
    "**Best practice:** Use `dict[str, T]` where the **key is the contract** with the config. This is refactor-safe - you can rename Python classes/functions without breaking configs.\n",
    "\n",
    "### 3.1 Extra Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "custom-transformers",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,080 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,081 | [INFO]: Running 'AddProcessedFlag' ... \n",
      "2026-02-09 09:50:33,081 | [INFO]: Completed 'AddProcessedFlag' in 0.0s \n",
      "2026-02-09 09:50:33,084 | [INFO]: Running 'DoubleAmount' ... \n",
      "2026-02-09 09:50:33,084 | [INFO]: Completed 'DoubleAmount' in 0.0s \n",
      "2026-02-09 09:50:33,084 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 5)\n",
      "┌──────────┬──────────┬────────┬────────┬───────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ processed │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---       │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ bool      │\n",
      "╞══════════╪══════════╪════════╪════════╪═══════════╡\n",
      "│ 1        ┆ alice    ┆ 300.0  ┆ US     ┆ true      │\n",
      "│ 2        ┆ bob      ┆ 150.0  ┆ EU     ┆ true      │\n",
      "└──────────┴──────────┴────────┴────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Define custom transformers\n",
    "class AddProcessedFlag(Transformer):\n",
    "    def _transform_nw(self, df):\n",
    "        import narwhals as nw\n",
    "        return df.with_columns(nw.lit(True).alias(\"processed\"))\n",
    "\n",
    "\n",
    "class DoubleAmount(Transformer):\n",
    "    def _transform_nw(self, df):\n",
    "        import narwhals as nw\n",
    "        return df.with_columns((nw.col(\"amount\") * 2).alias(\"amount\"))\n",
    "\n",
    "\n",
    "# Config references transformers by name (the dict key)\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\"transformer\": \"AddProcessedFlag\"},\n",
    "        {\"transformer\": \"DoubleAmount\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Pass custom transformers as dict[str, class]\n",
    "# Keys are the names used in config - decoupled from Python class names\n",
    "pipe = load_pipeline(\n",
    "    config,\n",
    "    extra_transformers={\n",
    "        \"AddProcessedFlag\": AddProcessedFlag,\n",
    "        \"DoubleAmount\": DoubleAmount,\n",
    "    }\n",
    ")\n",
    "\n",
    "result = pipe.run(orders.head(2))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refactor-safe",
   "metadata": {},
   "source": [
    "**Why dict keys matter for refactoring:**\n",
    "\n",
    "```python\n",
    "# If you rename DoubleAmount → MultiplyAmount in Python:\n",
    "extra_transformers={\n",
    "    \"DoubleAmount\": MultiplyAmount,  # Key stays same, config doesn't break\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-pattern",
   "metadata": {},
   "source": [
    "### 3.2 Using Modules\n",
    "\n",
    "For production, organize transformers in modules:\n",
    "\n",
    "```python\n",
    "# my_transformers.py\n",
    "__all__ = [\"AddProcessedFlag\", \"DoubleAmount\"]\n",
    "\n",
    "class AddProcessedFlag(Transformer): ...\n",
    "class DoubleAmount(Transformer): ...\n",
    "```\n",
    "\n",
    "```python\n",
    "# Load from module\n",
    "import my_transformers\n",
    "\n",
    "pipe = load_pipeline(config, extra_transformers=[my_transformers])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-functions-header",
   "metadata": {},
   "source": [
    "### 3.3 Extra Functions (for Split/Branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extra-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,089 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,089 | [INFO]: Entering split \n",
      "2026-02-09 09:50:33,097 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,097 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,097 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,097 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,097 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (2 transformations)\n",
      "------ SPLIT ------ (function: split_by_region)\n",
      "**SPLIT <<< international >>> (1 transformation):\n",
      "     - AddLiterals\n",
      "**SPLIT <<< us >>> (1 transformation):\n",
      "     - AddLiterals\n",
      "<<< Append DFs >>>\n",
      "shape: (5, 5)\n",
      "┌──────────┬──────────┬────────┬────────┬──────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ tax_rate │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---      │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ f64      │\n",
      "╞══════════╪══════════╪════════╪════════╪══════════╡\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ EU     ┆ 0.2      │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ APAC   ┆ 0.2      │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ EU     ┆ 0.2      │\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ US     ┆ 0.08     │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ US     ┆ 0.08     │\n",
      "└──────────┴──────────┴────────┴────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "def split_by_region(df):\n",
    "    \"\"\"Split DataFrame by region.\"\"\"\n",
    "    return {\n",
    "        \"us\": df.filter(pl.col(\"region\") == \"US\"),\n",
    "        \"international\": df.filter(pl.col(\"region\") != \"US\"),\n",
    "    }\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"split_function\": \"split_by_region\",  # References dict key\n",
    "    \"pipeline\": {\n",
    "        \"us\": [\n",
    "            {\"transformer\": \"AddLiterals\", \"params\": {\n",
    "                \"data\": [{\"alias\": \"tax_rate\", \"value\": 0.08}]\n",
    "            }}\n",
    "        ],\n",
    "        \"international\": [\n",
    "            {\"transformer\": \"AddLiterals\", \"params\": {\n",
    "                \"data\": [{\"alias\": \"tax_rate\", \"value\": 0.20}]\n",
    "            }}\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(\n",
    "    config,\n",
    "    extra_functions={\n",
    "        \"split_by_region\": split_by_region,  # Key matches config reference\n",
    "    }\n",
    ")\n",
    "\n",
    "pipe.show()\n",
    "result = pipe.run(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Lazy Parameters (`__ns__`)\n",
    "\n",
    "For runtime parameter resolution, use `lazy: true` with the `__ns__` prefix to reference values from nebula storage.\n",
    "\n",
    "See notebook 04 for `LazyWrapper` details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lazy-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,105 | [INFO]: Nebula Storage: clear. \n",
      "2026-02-09 09:50:33,105 | [INFO]: Nebula Storage: 0 keys remained after clearing. \n",
      "2026-02-09 09:50:33,105 | [INFO]: Nebula Storage: setting an object (<class 'str'>) with the key \"computed_label\". \n",
      "2026-02-09 09:50:33,105 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,105 | [INFO]: Running '(Lazy) AddLiterals' ... \n",
      "2026-02-09 09:50:33,105 | [INFO]: Completed '(Lazy) AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,105 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 6)\n",
      "┌──────────┬──────────┬────────┬────────┬────────────┬──────────────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ static_col ┆ dynamic_col      │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---        ┆ ---              │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ str        ┆ str              │\n",
      "╞══════════╪══════════╪════════╪════════╪════════════╪══════════════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ US     ┆ hardcoded  ┆ premium_customer │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ EU     ┆ hardcoded  ┆ premium_customer │\n",
      "└──────────┴──────────┴────────┴────────┴────────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "ns.clear()\n",
    "ns.set(\"computed_label\", \"premium_customer\")\n",
    "\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"transformer\": \"AddLiterals\",\n",
    "            \"lazy\": True,  # Enable lazy resolution\n",
    "            \"params\": {\n",
    "                \"data\": [\n",
    "                    {\"alias\": \"static_col\", \"value\": \"hardcoded\"},\n",
    "                    {\"alias\": \"dynamic_col\", \"value\": \"__ns__computed_label\"},  # Resolved at runtime\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "result = pipe.run(orders.head(2))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lazy-nested",
   "metadata": {},
   "source": [
    "The `__ns__` prefix works at any nesting depth within `params`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Loops (Dynamic Expansion)\n",
    "\n",
    "Loops let you generate repetitive pipeline sections dynamically. The `loop` block expands at load time, creating multiple transformers or pipelines from a template.\n",
    "\n",
    "### 5.1 Basic Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loop-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (3 transformations)\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'flag_a', 'value': True}]\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'flag_b', 'value': True}]\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'flag_c', 'value': True}]\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"loop\": {\n",
    "                \"values\": {\n",
    "                    \"col_name\": [\"flag_a\", \"flag_b\", \"flag_c\"]\n",
    "                },\n",
    "                \"transformer\": \"AddLiterals\",\n",
    "                \"params\": {\n",
    "                    \"data\": [{\"alias\": \"<<col_name>>\", \"value\": True}]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show(add_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "loop-basic-run",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,120 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,120 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,120 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,120 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,120 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,120 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,120 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,120 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 7)\n",
      "┌──────────┬──────────┬────────┬────────┬────────┬────────┬────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ flag_a ┆ flag_b ┆ flag_c │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ bool   ┆ bool   ┆ bool   │\n",
      "╞══════════╪══════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ US     ┆ true   ┆ true   ┆ true   │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ EU     ┆ true   ┆ true   ┆ true   │\n",
      "└──────────┴──────────┴────────┴────────┴────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "result = pipe.run(orders.head(2))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-modes",
   "metadata": {},
   "source": [
    "### 5.2 Loop Modes: Linear vs Product\n",
    "\n",
    "| Mode | Description |\n",
    "|------|-------------|\n",
    "| `linear` | Zip values together (default) |\n",
    "| `product` | Cartesian product of all values |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loop-linear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (2 transformations)\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'col_x', 'value': 100}]\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'col_y', 'value': 200}]\n"
     ]
    }
   ],
   "source": [
    "# Linear mode: zip([\"a\", \"b\"], [1, 2]) → [(\"a\", 1), (\"b\", 2)]\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"loop\": {\n",
    "                \"mode\": \"linear\",\n",
    "                \"values\": {\n",
    "                    \"name\": [\"col_x\", \"col_y\"],\n",
    "                    \"val\": [100, 200]\n",
    "                },\n",
    "                \"transformer\": \"AddLiterals\",\n",
    "                \"params\": {\n",
    "                    \"data\": [{\"alias\": \"<<name>>\", \"value\": \"<<val>>\"}]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show(add_params=True)\n",
    "# Creates: AddLiterals(col_x=100), AddLiterals(col_y=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "loop-product",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (4 transformations)\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'US_sales', 'value': 0}]\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'US_returns', 'value': 0}]\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'EU_sales', 'value': 0}]\n",
      " - AddLiterals -> PARAMS: data=[{'alias': 'EU_returns', 'value': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Product mode: product([\"a\", \"b\"], [1, 2]) → [(\"a\", 1), (\"a\", 2), (\"b\", 1), (\"b\", 2)]\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"loop\": {\n",
    "                \"mode\": \"product\",\n",
    "                \"values\": {\n",
    "                    \"prefix\": [\"US\", \"EU\"],\n",
    "                    \"metric\": [\"sales\", \"returns\"]\n",
    "                },\n",
    "                \"transformer\": \"AddLiterals\",\n",
    "                \"params\": {\n",
    "                    \"data\": [{\"alias\": \"<<prefix>>_<<metric>>\", \"value\": 0}]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show(add_params=True)\n",
    "# Creates 4 transformers: US_sales, US_returns, EU_sales, EU_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-pipeline",
   "metadata": {},
   "source": [
    "### 5.3 Loop Over Pipelines\n",
    "\n",
    "Loops can generate entire pipelines (with branches):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "loop-with-branch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,140 | [INFO]: Nebula Storage: clear. \n",
      "2026-02-09 09:50:33,140 | [INFO]: Nebula Storage: 0 keys remained after clearing. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (4 transformations)\n",
      "   --> Store df with key \"original\"\n",
      "*** Pipeline *** (2 transformations)\n",
      "------ BRANCH (from storage: original) ------\n",
      ">> Branch (2 transformations):\n",
      "     - SelectColumns -> PARAMS: columns=['order_id']\n",
      "     - AddLiterals -> PARAMS: data=[{'alias': 'metric_a', 'value': 10}]\n",
      "<<< Join DFs >>>\n",
      "  - how: left\n",
      "  - on: order_id\n",
      "*** Pipeline *** (2 transformations)\n",
      "------ BRANCH (from storage: original) ------\n",
      ">> Branch (2 transformations):\n",
      "     - SelectColumns -> PARAMS: columns=['order_id']\n",
      "     - AddLiterals -> PARAMS: data=[{'alias': 'metric_b', 'value': 20}]\n",
      "<<< Join DFs >>>\n",
      "  - how: left\n",
      "  - on: order_id\n"
     ]
    }
   ],
   "source": [
    "ns.clear()\n",
    "\n",
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\"store\": \"original\"},  # Store for branch to read\n",
    "        {\n",
    "            \"loop\": {\n",
    "                \"mode\": \"linear\",\n",
    "                \"values\": {\n",
    "                    \"col_name\": [\"metric_a\", \"metric_b\"],\n",
    "                    \"col_value\": [10, 20]\n",
    "                },\n",
    "                \"branch\": {\n",
    "                    \"storage\": \"original\",\n",
    "                    \"end\": \"join\",\n",
    "                    \"on\": \"order_id\",\n",
    "                    \"how\": \"left\"\n",
    "                },\n",
    "                \"pipeline\": [\n",
    "                    {\"transformer\": \"SelectColumns\", \"params\": {\"columns\": [\"order_id\"]}},\n",
    "                    {\"transformer\": \"AddLiterals\", \"params\": {\n",
    "                        \"data\": [{\"alias\": \"<<col_name>>\", \"value\": \"<<col_value>>\"}]\n",
    "                    }}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show(add_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loop-branch-run",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,147 | [INFO]: Starting pipeline \n",
      "2026-02-09 09:50:33,147 | [INFO]:    --> Store df with key \"original\" \n",
      "2026-02-09 09:50:33,147 | [INFO]: Nebula Storage: setting an object (<class 'polars.dataframe.frame.DataFrame'>) with the key \"original\". \n",
      "2026-02-09 09:50:33,147 | [INFO]: Entering branch \n",
      "2026-02-09 09:50:33,147 | [INFO]: Running 'SelectColumns' ... \n",
      "2026-02-09 09:50:33,147 | [INFO]: Completed 'SelectColumns' in 0.0s \n",
      "2026-02-09 09:50:33,147 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,147 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,147 | [INFO]: Entering branch \n",
      "2026-02-09 09:50:33,147 | [INFO]: Running 'SelectColumns' ... \n",
      "2026-02-09 09:50:33,147 | [INFO]: Completed 'SelectColumns' in 0.0s \n",
      "2026-02-09 09:50:33,147 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,147 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,147 | [INFO]: Pipeline completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌──────────┬──────────┬────────┬────────┬──────────┬──────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ metric_a ┆ metric_b │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---      ┆ ---      │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ i32      ┆ i32      │\n",
      "╞══════════╪══════════╪════════╪════════╪══════════╪══════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ US     ┆ 10       ┆ 20       │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ EU     ┆ 10       ┆ 20       │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ US     ┆ 10       ┆ 20       │\n",
      "└──────────┴──────────┴────────┴────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "result = pipe.run(orders.head(3))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-skip",
   "metadata": {},
   "source": [
    "### 5.4 Skip/Perform with Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "loop-skip-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline *** (1 transformation)\n",
      " - SelectColumns\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"skip\": True,  # Entire loop is skipped\n",
    "            \"loop\": {\n",
    "                \"values\": {\"x\": [1, 2, 3]},\n",
    "                \"transformer\": \"AssertNotEmpty\"  # Never runs\n",
    "            }\n",
    "        },\n",
    "        {\"transformer\": \"SelectColumns\", \"params\": {\"glob\": \"*\"}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show()  # Only SelectColumns appears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Complete Examples\n",
    "\n",
    "### 6.1 Split Pipeline in Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "complete-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,166 | [INFO]: Starting pipeline 'Value-Based Processing' \n",
      "2026-02-09 09:50:33,166 | [INFO]: Entering split \n",
      "2026-02-09 09:50:33,166 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,173 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,173 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,173 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,173 | [INFO]: Pipeline 'Value-Based Processing' completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Value-Based Processing *** (2 transformations)\n",
      "------ SPLIT ------ (function: split_by_value)\n",
      "**SPLIT <<< high >>> (1 transformation):\n",
      "     - AddLiterals\n",
      "**SPLIT <<< low >>> (1 transformation):\n",
      "     - AddLiterals\n",
      "<<< Append DFs >>>\n",
      "shape: (5, 5)\n",
      "┌──────────┬──────────┬────────┬────────┬──────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ priority │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---      │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ str      │\n",
      "╞══════════╪══════════╪════════╪════════╪══════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ US     ┆ high     │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ US     ┆ high     │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ EU     ┆ high     │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ EU     ┆ standard │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ APAC   ┆ standard │\n",
      "└──────────┴──────────┴────────┴────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "def split_by_value(df):\n",
    "    return {\n",
    "        \"high\": df.filter(pl.col(\"amount\") >= 150),\n",
    "        \"low\": df.filter(pl.col(\"amount\") < 150),\n",
    "    }\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"name\": \"Value-Based Processing\",\n",
    "    \"split_function\": \"split_by_value\",\n",
    "    \"split_order\": [\"high\", \"low\"],\n",
    "    \"pipeline\": {\n",
    "        \"high\": [\n",
    "            {\"transformer\": \"AddLiterals\", \"params\": {\n",
    "                \"data\": [{\"alias\": \"priority\", \"value\": \"high\"}]\n",
    "            }}\n",
    "        ],\n",
    "        \"low\": [\n",
    "            {\"transformer\": \"AddLiterals\", \"params\": {\n",
    "                \"data\": [{\"alias\": \"priority\", \"value\": \"standard\"}]\n",
    "            }}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config, extra_functions={\"split_by_value\": split_by_value})\n",
    "pipe.show()\n",
    "\n",
    "result = pipe.run(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-branch",
   "metadata": {},
   "source": [
    "### 6.2 Branch Pipeline in Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "branch-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,180 | [INFO]: Nebula Storage: clear. \n",
      "2026-02-09 09:50:33,180 | [INFO]: Nebula Storage: 0 keys remained after clearing. \n",
      "2026-02-09 09:50:33,180 | [INFO]: Nebula Storage: setting an object (<class 'polars.dataframe.frame.DataFrame'>) with the key \"customer_tiers\". \n",
      "2026-02-09 09:50:33,180 | [INFO]: Starting pipeline 'Enrich with Customer Tier' \n",
      "2026-02-09 09:50:33,180 | [INFO]: Entering branch \n",
      "2026-02-09 09:50:33,180 | [INFO]: Running 'SelectColumns' ... \n",
      "2026-02-09 09:50:33,180 | [INFO]: Completed 'SelectColumns' in 0.0s \n",
      "2026-02-09 09:50:33,180 | [INFO]: Pipeline 'Enrich with Customer Tier' completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Enrich with Customer Tier *** (1 transformation)\n",
      "------ BRANCH (from storage: customer_tiers) ------\n",
      ">> Branch (1 transformation):\n",
      "     - SelectColumns\n",
      "<<< Join DFs >>>\n",
      "shape: (5, 5)\n",
      "┌──────────┬──────────┬────────┬────────┬────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ tier   │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---    │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ str    │\n",
      "╞══════════╪══════════╪════════╪════════╪════════╡\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ US     ┆ gold   │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ EU     ┆ silver │\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ US     ┆ gold   │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ APAC   ┆ bronze │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ EU     ┆ silver │\n",
      "└──────────┴──────────┴────────┴────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "ns.clear()\n",
    "\n",
    "# Pre-store customer tiers\n",
    "tiers = pl.DataFrame({\n",
    "    \"customer\": [\"alice\", \"bob\", \"carol\"],\n",
    "    \"tier\": [\"gold\", \"silver\", \"bronze\"]\n",
    "})\n",
    "ns.set(\"customer_tiers\", tiers)\n",
    "\n",
    "config = {\n",
    "    \"name\": \"Enrich with Customer Tier\",\n",
    "    \"branch\": {\n",
    "        \"storage\": \"customer_tiers\",\n",
    "        \"end\": \"join\",\n",
    "        \"on\": \"customer\",\n",
    "        \"how\": \"left\"\n",
    "    },\n",
    "    \"pipeline\": [\n",
    "        {\"transformer\": \"SelectColumns\", \"params\": {\"columns\": [\"customer\", \"tier\"]}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show()\n",
    "\n",
    "result = pipe.run(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-apply",
   "metadata": {},
   "source": [
    "### 6.3 Apply-to-Rows in Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apply-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,191 | [INFO]: Starting pipeline 'Discount High-Value Orders' \n",
      "2026-02-09 09:50:33,195 | [INFO]: Entering apply_to_rows \n",
      "2026-02-09 09:50:33,196 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,197 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,198 | [INFO]: Running 'AddLiterals' ... \n",
      "2026-02-09 09:50:33,199 | [INFO]: Completed 'AddLiterals' in 0.0s \n",
      "2026-02-09 09:50:33,200 | [INFO]: Pipeline 'Discount High-Value Orders' completed in 0.0s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Discount High-Value Orders *** (2 transformations)\n",
      "------ APPLY TO ROWS (amount ge 200) ------\n",
      ">> Apply To rows (1 transformation):\n",
      "     - AddLiterals\n",
      ">> Otherwise (1 transformation)\n",
      "     - AddLiterals\n",
      "<<< Append DFs >>>\n",
      "shape: (5, 5)\n",
      "┌──────────┬──────────┬────────┬────────┬──────────┐\n",
      "│ order_id ┆ customer ┆ amount ┆ region ┆ discount │\n",
      "│ ---      ┆ ---      ┆ ---    ┆ ---    ┆ ---      │\n",
      "│ i64      ┆ str      ┆ f64    ┆ str    ┆ f64      │\n",
      "╞══════════╪══════════╪════════╪════════╪══════════╡\n",
      "│ 3        ┆ alice    ┆ 200.0  ┆ US     ┆ 0.1      │\n",
      "│ 5        ┆ bob      ┆ 300.0  ┆ EU     ┆ 0.1      │\n",
      "│ 1        ┆ alice    ┆ 150.0  ┆ US     ┆ 0.0      │\n",
      "│ 2        ┆ bob      ┆ 75.0   ┆ EU     ┆ 0.0      │\n",
      "│ 4        ┆ carol    ┆ 50.0   ┆ APAC   ┆ 0.0      │\n",
      "└──────────┴──────────┴────────┴────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"name\": \"Discount High-Value Orders\",\n",
    "    \"apply_to_rows\": {\n",
    "        \"input_col\": \"amount\",\n",
    "        \"operator\": \"ge\",\n",
    "        \"value\": 200\n",
    "    },\n",
    "    \"pipeline\": [\n",
    "        {\"transformer\": \"AddLiterals\", \"params\": {\n",
    "            \"data\": [{\"alias\": \"discount\", \"value\": 0.10}]\n",
    "        }}\n",
    "    ],\n",
    "    \"otherwise\": [\n",
    "        {\"transformer\": \"AddLiterals\", \"params\": {\n",
    "            \"data\": [{\"alias\": \"discount\", \"value\": 0.0}]\n",
    "        }}\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "pipe.show()\n",
    "\n",
    "result = pipe.run(orders)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Feature | Syntax |\n",
    "|---------|--------|\n",
    "| Basic transformer | `{\"transformer\": \"Name\", \"params\": {...}}` |\n",
    "| Skip/disable | `\"skip\": true` or `\"perform\": false` |\n",
    "| Description | `\"description\": \"Human-readable text\"` |\n",
    "| Lazy params | `\"lazy\": true` + `\"__ns__key\"` in params |\n",
    "| Storage | `{\"store\": \"key\"}`, `{\"store_debug\": \"key\"}` |\n",
    "| Loops | `{\"loop\": {\"values\": {...}, \"transformer\": ...}}` |\n",
    "| Custom transformers | `extra_transformers={\"Name\": Class}` |\n",
    "| Custom functions | `extra_functions={\"name\": func}` |\n",
    "\n",
    "**Best practices:**\n",
    "- Use `dict[str, T]` for extras (refactor-safe)\n",
    "- Keep config keys stable, even if Python names change\n",
    "- Use `skip`/`perform` for feature flags\n",
    "- Organize custom transformers in modules with `__all__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-09 09:50:33,207 | [INFO]: Nebula Storage: clear. \n",
      "2026-02-09 09:50:33,207 | [INFO]: Nebula Storage: 0 keys remained after clearing. \n"
     ]
    }
   ],
   "source": [
    "ns.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
